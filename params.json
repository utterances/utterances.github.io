{"name":"Qi's portfolio","tagline":"work in progress, excuse the duct-tape","body":"## Interaction Design Research\r\n### Mobile Multi-touch Visual Programming Environment\r\n![tapperware overview](http://www-personal.umich.edu/~yangqi/portfolio/images/multi-overview.jpg)\r\nTo examine visual feedback in multi-touch interaction design, I built a visual programming environment for multi-touch tablet for assembling interfaces. This serves as a platform to explore visual feedback in multi-touch interactions. Multiple visual feedback paradigms are implemented on top of a common core visual vocabulary, consisted of visual entities such as regions and links and containers.\r\n\r\nThis environment can be used to rapidly construct musical instruments, sample tasks were designed and used in human-subject usability study. In these example, a musical keyboard and multi-touch mixer instrument is built.\r\n[![task video](http://www-personal.umich.edu/~yangqi/portfolio/images/multi-example.jpg)](https://vimeo.com/116926224)\r\n[Video: Task 1](https://vimeo.com/116926224),\r\n[Video: Task 2](https://vimeo.com/116926223)\r\n\r\n**Tools**: [urMus](http://urmus.eecs.umich.edu), Lua, iOS\r\n\r\nPublication pending\r\n___\r\n\r\n### Gesture-augmented Keyboard Instrument\r\n[![keyboard setup](http://www-personal.umich.edu/~yangqi/portfolio/images/key-overview.jpg)](https://vimeo.com/44947845)\r\n[Video demo](https://vimeo.com/44947845)\r\n\r\nUsing Kinect Depth sensor to augment traditional keyboard instrument with a 3D gesture space, and top-down projection is used for visual feedback at the site of the gesture interaction.\r\n\r\nThis novel interaction model enables us to explore different visualizations:\r\n![keyboard visualization](http://www-personal.umich.edu/~yangqi/portfolio/images/key-vis.jpg)\r\n\r\n**Tools**: Kinect, Processing, OpenFrameworks, OpenCV\r\n\r\n#### Publication\r\n*Evaluating Gesture-Augmented Piano Performance*, Qi Yang, Georg Essl \r\n[CMJ 2014](http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_a_00277) [PDF](http://www-personal.umich.edu/~yangqi/pubs/CMJ2014Yang.pdf)\r\n\r\n*Visual Associations in Augmented Keyboard Performance*, Qi Yang, Georg Essl \r\n[NIME 2013](http://www-personal.umich.edu/~yangqi/pubs/NIME13Yang.pdf)\r\n\r\n*Augmented Piano Performance using a Depth Camera*, Qi Yang, Georg Essl \r\n[NIME 2012](http://www-personal.umich.edu/~yangqi/pubs/NIME12Yang.pdf)\r\n___\r\n\r\n## Mobile Phone Sensor Data Analysis\r\n[![hourly visualization](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-hourly-thumb.jpg)](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-hourly.jpg)\r\n_Visualizing contact network between 6 dormitories, by hour of day_\r\n\r\nAs part of the ExFlu study by University of Michigan School of Public Health, I cleaned and analyzed multi-sensory data collected from 100 phones over 3 month. These include bluetooth and wifi contacts, accelerometer, and battery. Between-phone Bluetooth contact data are used to visualize social contact between study participants.\r\n\r\nI also coordinated the collection of GPS position of local wifi access points. These data enabled me to localize and visualize activities on-campus and heat spots.\r\n[![map](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-map-thumb.jpg)](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-map.jpg)\r\n\r\n**Tools**: Python, MSSQL, kml, matplotlib\r\n___\r\n\r\n## Web Development & User Experience Design\r\n[![harvest](http://www-personal.umich.edu/~yangqi/portfolio/images/harvest-thumb.jpg)](http://www-personal.umich.edu/~yangqi/portfolio/images/harvest.jpg)\r\nI developed as part of the web development team of Harvest Mission Community Church. I also lead the upcoming redesign of the web presence of the nonprofit organization.\r\n\r\n**Tools**: PHP, html+CSS, Sketch\r\n___\r\n\r\n## Mobile Security\r\n![attack](http://www-personal.umich.edu/~yangqi/portfolio/images/attack.jpg)\r\nWe created a mobile phishing attack and proof-of-concept defense against the attack for computer security graduate course project. The demonstration attack targets the mobile browser, implemented for iOS, by mimicking the native application user interface to pass casual observation.\r\n\r\n[Paper](http://www-personal.umich.edu/~yangqi/pivot/mobile_phishing_defense.pdf)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}