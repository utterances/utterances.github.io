### Interaction Design Research
#### Multi-touch Visual Environment for Mobile
![tapperware overview](http://www-personal.umich.edu/~yangqi/portfolio/images/multi-overview.jpg)
To examine visual feedback in multi-touch interaction design, I built a visual programming environment for multi-touch tablet for assembling interfaces. This serves as a platform to explore visual feedback in multi-touch interactions. Multiple visual feedback paradigms are implemented on top of a common core visual vocabulary, consisted of visual entities such as regions and links and containers.

This environment can be used to rapidly construct musical instruments, sample tasks were designed and used in human-subject usability study. In these example, a musical keyboard and multi-touch mixer instrument is built.
[![task video](http://www-personal.umich.edu/~yangqi/portfolio/images/multi-example.jpg)](https://vimeo.com/116926224)
[Video: Task 1](https://vimeo.com/116926224),
[Video: Task 2](https://vimeo.com/116926223)

##### Tools
[urMus](http://urmus.eecs.umich.edu), a cross-platform audio and visual interaction environment, Lua, iOS.

Publication pending

#### Gesture-augmented Keyboard Instrument
[![keyboard setup](http://www-personal.umich.edu/~yangqi/portfolio/images/key-overview.jpg)](https://vimeo.com/44947845)
[Video demo](https://vimeo.com/44947845)

Using Kinect Depth sensor to augment traditional keyboard instrument with a 3D gesture space, and top-down projection is used for visual feedback at the site of the gesture interaction.

This novel interaction model enables us to explore different visualizations:
![keyboard visualization](http://www-personal.umich.edu/~yangqi/portfolio/images/key-vis.jpg)

##### Publication
*Evaluating Gesture-Augmented Piano Performance*, Qi Yang, Georg Essl [CMJ 2014](http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_a_00277)
[PDF](http://www-personal.umich.edu/~yangqi/pubs/CMJ2014Yang.pdf)

*Visual Associations in Augmented Keyboard Performance*, Qi Yang, Georg Essl 	[NIME 2013](http://www-personal.umich.edu/~yangqi/pubs/NIME13Yang.pdf)

*Augmented Piano Performance using a Depth Camera*, Qi Yang, Georg Essl [NIME 2012](http://www-personal.umich.edu/~yangqi/pubs/NIME12Yang.pdf)

### Mobile Phone Sensor Data Analysis
[![hourly visualization](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-hourly-thumb.jpg)](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-hourly.jpg)
_Contact network between 6 dormitory, by hour of day_

As part of the ExFlu study by University of Michigan School of Public Health, I cleaned and analyzed multi-sensory data collected from 100 phones over 3 month. These include bluetooth and wifi contacts, accelerometer, and battery. Between-phone Bluetooth contact data are used to visualize social contact between study participants.

I also coordinated the collection of GPS position of local wifi access points. These data enabled me to localize and visualize activities on-campus and heat spots.
[![map](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-map-thumb.jpg)](http://www-personal.umich.edu/~yangqi/portfolio/images/iepi-map.jpg)

##### Tools
Python, MSSQL, kml, matplotlib

### Web Development & User Experience
I worked as part of the web development team of Harvest Mission Community Church to develop 


### Mobile Security
![attack](http://www-personal.umich.edu/~yangqi/portfolio/images/attack.jpg)
We created a mobile phishing attack and proof-of-concept defense against the attack for computer security graduate course project. The demonstration attack targets the mobile browser, implemented for iOS, by mimicking the native application user interface to pass casual observation.

[Paper](http://www-personal.umich.edu/~yangqi/pivot/mobile_phishing_defense.pdf)
