<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Qi&#39;s portfolio by utterances</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Qi&#39;s portfolio</h1>
        <p>work in progress, excuse the duct-tape</p>


        <p class="view"><a href="https://github.com/utterances">View My GitHub Profile</a></p>

      </header>
      <section>
        <h2>
<a id="interaction-design-research" class="anchor" href="#interaction-design-research" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interaction Design Research</h2>

<h3>
<a id="mobile-multi-touch-visual-programming-environment" class="anchor" href="#mobile-multi-touch-visual-programming-environment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mobile Multi-touch Visual Programming Environment</h3>

<p><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/multi-overview.jpg" alt="tapperware overview">
To examine visual feedback in multi-touch interaction design, I built a visual programming environment for multi-touch tablet for assembling interfaces. This serves as a platform to explore visual feedback in multi-touch interactions. Multiple visual feedback paradigms are implemented on top of a common core visual vocabulary, consisted of visual entities such as regions and links and containers.</p>

<p>This environment can be used to rapidly construct musical instruments, sample tasks were designed and used in human-subject usability study. In these example, a musical keyboard and multi-touch mixer instrument is built.
<a href="https://vimeo.com/116926224"><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/multi-example.jpg" alt="task video"></a>
<a href="https://vimeo.com/116926224">Video: Task 1</a>,
<a href="https://vimeo.com/116926223">Video: Task 2</a></p>

<p><strong>Tools</strong>: <a href="http://urmus.eecs.umich.edu">urMus</a>, Lua, iOS</p>

<p>Publication pending</p>

<hr>

<h3>
<a id="gesture-augmented-keyboard-instrument" class="anchor" href="#gesture-augmented-keyboard-instrument" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gesture-augmented Keyboard Instrument</h3>

<p><a href="https://vimeo.com/44947845"><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/key-overview.jpg" alt="keyboard setup"></a>
<a href="https://vimeo.com/44947845">Video demo</a></p>

<p>Using Kinect Depth sensor to augment traditional keyboard instrument with a 3D gesture space, and top-down projection is used for visual feedback at the site of the gesture interaction.</p>

<p>This novel interaction model enables us to explore different visualizations:
<img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/key-vis.jpg" alt="keyboard visualization"></p>

<p><strong>Tools</strong>: Kinect, <a href="https://processing.org">Processing</a>, <a href="http://openframeworks.cc">OpenFrameworks</a>, <a href="http://opencv.org">OpenCV</a></p>

<h4>
<a id="publication" class="anchor" href="#publication" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publication</h4>

<p><em>Evaluating Gesture-Augmented Piano Performance</em>, Qi Yang, Georg Essl 
<a href="http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_a_00277">CMJ 2014</a> <a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/pubs/CMJ2014Yang.pdf">PDF</a></p>

<p><em>Visual Associations in Augmented Keyboard Performance</em>, Qi Yang, Georg Essl 
<a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/pubs/NIME13Yang.pdf">NIME 2013</a></p>

<p><em>Augmented Piano Performance using a Depth Camera</em>, Qi Yang, Georg Essl 
<a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/pubs/NIME12Yang.pdf">NIME 2012</a></p>

<hr>

<h2>
<a id="mobile-phone-sensor-data-analysis" class="anchor" href="#mobile-phone-sensor-data-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mobile Phone Sensor Data Analysis</h2>

<p><a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/iepi-hourly.jpg"><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/iepi-hourly-thumb.jpg" alt="hourly visualization"></a>
<em>Visualizing contact network between 6 dormitories, by hour of day</em></p>

<p>As part of the ExFlu study by University of Michigan School of Public Health, I cleaned and analyzed multi-sensory data collected from 100 phones over 3 month. These include bluetooth and wifi contacts, accelerometer, and battery. Between-phone Bluetooth contact data are used to visualize social contact between study participants.</p>

<p>I also coordinated the collection of GPS position of local wifi access points. These data enabled me to localize and visualize activities on-campus and heat spots.
<a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/iepi-map.jpg"><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/iepi-map-thumb.jpg" alt="map"></a></p>

<p><strong>Tools</strong>: Python, MSSQL, kml, matplotlib</p>

<hr>

<h2>
<a id="user-interface--product-concept-development" class="anchor" href="#user-interface--product-concept-development" aria-hidden="true"><span class="octicon octicon-link"></span></a>User Interface / Product Concept Development</h2>

<p><a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/livewriting.jpg"><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/livewriting-thumb.jpg" alt="livewriter"></a>
In collaboration with <a href="http://web.eecs.umich.edu/%7Esnaglee/">Sang Won Lee</a>, I developed user interface and product concepts for a web-based writing application and corresponding mobile app which supports timed playback of the writing process, as well as enabling user to express emotion through typing gestures.</p>

<hr>

<h2>
<a id="web-development--user-experience-design" class="anchor" href="#web-development--user-experience-design" aria-hidden="true"><span class="octicon octicon-link"></span></a>Web Development &amp; User Experience Design</h2>

<p><a href="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/harvest.jpg"><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/harvest-thumb.jpg" alt="harvest"></a>
I developed as part of the web development team of Harvest Mission Community Church. I also lead the upcoming redesign of the web presence of the nonprofit organization.</p>

<p><strong>Tools</strong>: PHP, html+CSS, Sketch</p>

<hr>

<h2>
<a id="mobile-security" class="anchor" href="#mobile-security" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mobile Security</h2>

<p><img src="http://www-personal.umich.edu/%7Eyangqi/portfolio/images/attack.jpg" alt="attack">
We created a mobile phishing attack and proof-of-concept defense against the attack for computer security graduate course project. The demonstration attack targets the mobile browser, implemented for iOS, by mimicking the native application user interface to pass casual observation.</p>

<p><a href="http://www-personal.umich.edu/%7Eyangqi/pivot/mobile_phishing_defense.pdf">Paper</a></p>
      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>